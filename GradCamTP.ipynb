{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a94634",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Índice\n",
    "\n",
    "1. **Introducción**\n",
    "   a. Explicaciones visuales en modelos de redes profundas  \n",
    "2. **Antecedentes**  \n",
    "   a. Oclussion Maps  \n",
    "   b. Guided Backpropagation  \n",
    "   c. CAM  \n",
    "3. **GradCAM**  \n",
    "   a. Explicación  \n",
    "   b. Ejemplos clasificación: ResNet50, VGG16, etc.  \n",
    "   c. Ejemplos otras tareas: Automatic Captioning  \n",
    "   d. Ventajas y desventajas  \n",
    "4. **Mejoras: GradCAM++ y otros métodos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54205a6e",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf99b1",
   "metadata": {},
   "source": [
    "# 1. Introducción\n",
    "\n",
    "La explicabilidad en redes neuronales convolucionales (CNN) ha surgido como un aspecto clave en el campo del reconocimiento de patrones, donde no solo interesa alcanzar un alto desempeño, sino también comprender qué información utiliza la red para tomar decisiones. Un primer avance fue **Class Activation Mapping (CAM, 2016)**, que permitió visualizar las regiones más relevantes de una imagen para la clasificación, aunque con la limitación de aplicarse únicamente a arquitecturas específicas con *global average pooling*. Más adelante, **Grad-CAM (2017)** amplió esta idea utilizando gradientes retropropagados, logrando un método versátil aplicable a una amplia variedad de arquitecturas y consolidándose como la técnica de referencia en explicabilidad. A partir de allí se desarrollaron extensiones como **Grad-CAM++ (2018)**, que mejora la localización en escenarios complejos, y **Score-CAM (2019)**, que evita depender directamente de los gradientes. Sin embargo, el salto conceptual decisivo que abrió la puerta al estudio moderno de la explicabilidad fue el de Grad-CAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b681c9",
   "metadata": {},
   "source": [
    "# 2. Antecedentes\n",
    "\n",
    "MINI TEXTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45de79",
   "metadata": {},
   "source": [
    "### Occlusion Maps\n",
    "\n",
    "**Occlusion Maps** es uno de los métodos más intuitivos y directos para generar explicaciones visuales en redes neuronales. La idea central consiste en evaluar la sensibilidad de la predicción de la red cuando partes de la entrada son ocultadas o reemplazadas por un valor neutro (por ejemplo, un parche negro o ruido). En la práctica, se recorre la imagen aplicando una “ventana de oclusión” que cubre sistemáticamente diferentes regiones, y se mide cómo varía la probabilidad asociada a la clase objetivo. Las zonas donde la predicción se ve más afectada se interpretan como las más relevantes para la decisión del modelo.  \n",
    "\n",
    "Este enfoque tiene varias ventajas: es sencillo de implementar, no depende de modificaciones en la arquitectura del modelo ni de los gradientes, y produce mapas de importancia fáciles de interpretar. No obstante, también presenta desventajas: es computacionalmente costoso (ya que requiere múltiples inferencias por imagen), la resolución depende del tamaño del parche usado, y no captura bien interacciones complejas entre diferentes regiones de la entrada. A pesar de estas limitaciones, Occlusion Maps es un método de referencia en la literatura y se utiliza frecuentemente como baseline en estudios de explicabilidad.  \n",
    "\n",
    "**Referencias:**  \n",
    "- Zeiler, M. D., & Fergus, R. (2014). *Visualizing and Understanding Convolutional Networks*. In ECCV. Springer.  \n",
    "- Samek, W., Montavon, G., Vedaldi, A., Hansen, L. K., & Müller, K. R. (Eds.). (2019). *Explainable AI: Interpreting, Explaining and Visualizing Deep Learning*. Springer.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e509c",
   "metadata": {},
   "source": [
    "### Guided Backpropagation\n",
    "\n",
    "**Guided Backpropagation** es un método de visualización que busca identificar qué regiones de una imagen influyen positivamente en la activación de una clase objetivo dentro de una red neuronal profunda. A diferencia del backpropagation estándar, este enfoque modifica el flujo de gradientes en las funciones de activación ReLU, permitiendo únicamente el paso de aquellos gradientes positivos asociados a activaciones positivas. El resultado es un mapa de sensibilidad de alta resolución que resalta bordes y detalles finos de la entrada, mostrando qué píxeles contribuyen a la predicción. Sin embargo, no es estrictamente clase-específico, ya que puede resaltar patrones que activan la red independientemente de la salida seleccionada. Por este motivo, suele utilizarse en combinación con Grad-CAM, logrando visualizaciones más interpretables y centradas en la clase de interés.  \n",
    "\n",
    "**Referencias:**  \n",
    "- Springenberg, J. T., Dosovitskiy, A., Brox, T., & Riedmiller, M. (2014). *Striving for Simplicity: The All Convolutional Net*. arXiv:1412.6806.  \n",
    "- Montavon, G., Samek, W., & Müller, K. R. (2018). *Methods for interpreting and understanding deep neural networks*. Digital Signal Processing, 73, 1–15.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a40d103",
   "metadata": {},
   "source": [
    "### CAM\n",
    "\n",
    "**CAM** fue introducido por Zhou et al. (2016) y se basa en la utilización de una capa de *global average pooling (GAP)* antes de la capa final de clasificación. La idea es que los pesos de la capa de salida pueden emplearse para ponderar los mapas de activación de la última capa convolucional, generando así un mapa de calor que indica las regiones de la imagen más relevantes para una clase determinada.\n",
    "\n",
    "Se contruyen los mapas de activacion para cada clase de interes como:\n",
    "\n",
    "$$\n",
    "M_c(x,y) = \\sum_k w_k^c f_k(x,y)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "* $M_c(x,y)$ es el mapa de activación para la clase $c$,\n",
    "* $f_k(x,y)$ es el mapa de activación de la característica $k$,\n",
    "* $w_k^c$ es el peso asociado a la clase $c$ en la capa de salida.\n",
    "\n",
    "\n",
    "Además de requerir global average pooling, CAM solo puede aplicarse a capas cuya ultima capa sea una red densa.\n",
    "Un uso interesante es la posibilidad de hacer localizacion de objetos mediante una red que no haya sido entrenada con bounding boxes http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf\n",
    "\n",
    "**Referencia:**\n",
    "Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., & Torralba, A. (2016). *Learning Deep Features for Discriminative Localization*. CVPR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5bda27",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Grad-CAM\n",
    "\n",
    "\n",
    "### Metodología\n",
    "\n",
    "**(CONVERTIR PRINCIPALMENTE EN UN PARRAFO - AGREGAR UNA INTUICIÓN)**\n",
    "Grad-CAM es una técnica que permite visualizar las regiones de una imagen que son relevantes para la decisión de un modelo de red neuronal. A través del uso de gradientes, se puede obtener un mapa de calor que indica qué partes de la imagen contribuyen más a la activación de una clase específica. Esto se logra calculando los gradientes de la clase de interés respecto a los mapas de activación de una capa convolucional, lo que permite ponderar las características de acuerdo con su importancia para la predicción.\n",
    "\n",
    "**Aporte:**\n",
    "Grad-CAM, propuesto por Selvaraju et al. (2017), generaliza la idea de CAM para que pueda aplicarse a una gran variedad de arquitecturas. Utiliza los gradientes de la clase de interés respecto a los mapas de activación de una capa convolucional, ponderando las características de acuerdo con su importancia para la predicción.\n",
    "\n",
    "**Fórmula principal:**\n",
    "\n",
    "1. Calcular los gradientes de la puntuación de la clase $y^c$ respecto a los mapas de activación $A^k$:\n",
    "\n",
    "$$\n",
    "\\alpha_k^c = \\frac{1}{Z} \\sum_i \\sum_j \\frac{\\partial y^c}{\\partial A_{ij}^k}\n",
    "$$\n",
    "\n",
    "2. Generar el mapa de activación como:\n",
    "\n",
    "$$\n",
    "L_{\\text{Grad-CAM}}^c = ReLU\\left(\\sum_k \\alpha_k^c A^k \\right)\n",
    "$$\n",
    "\n",
    "donde $ReLU$ asegura que solo se conserven las contribuciones positivas.\n",
    "\n",
    "**Ventajas:**\n",
    "\n",
    "* Se puede aplicar a múltiples arquitecturas (sin necesidad de GAP).\n",
    "* Permite obtener explicaciones visuales interpretables en tareas de clasificación, detección y segmentación.\n",
    "\n",
    "**Limitaciones:**\n",
    "\n",
    "* La resolución espacial del mapa depende de la capa elegida (generalmente baja).\n",
    "* Tiende a resaltar regiones amplias sin un detalle fino de contornos.\n",
    "\n",
    "**Referencia:**\n",
    "Selvaraju, R. R., et al. (2017). *Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization*. ICCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb83d59",
   "metadata": {},
   "source": [
    "#### Ejemplo 1 de Grad-CAM:clasificacion de imagenes con ResNet50 \n",
    "\n",
    "**Figura 1**\n",
    "Ejemplo con un modelo y gradcam, varias instancias y varias clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b54a5b",
   "metadata": {},
   "source": [
    "#### Ejemplo 2 de Grad-CAM: XXXX\n",
    "\n",
    "**Figura 2**: Segmentación/captioning/etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f342b0",
   "metadata": {},
   "source": [
    "#### Ejemplo 3 de varias arquitecturas\n",
    "\n",
    "**Figura 3** Ejemplo de varias arquitecturas\n",
    "\n",
    "                    modelo1                    modelo2\n",
    "            cat1|cat2  perro1|perro2    cat1|cat2  perro1|perro2\n",
    "\n",
    "instancia1\n",
    "\n",
    "instancia2\n",
    "\n",
    "instancia3\n",
    "\n",
    "instancia4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc263e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62126531",
   "metadata": {},
   "source": [
    "# 4. Más allá de Grad-CAM\n",
    "\n",
    "Con la intención de mejorar la definición y la estabilidad de los mapas de calor explicativos, se han propuesto diversas variantes de Grad-CAM. Estas buscan refinar la localización, reducir la dependencia de los gradientes o aumentar la resolución espacial de las visualizaciones.\n",
    "\n",
    "### Grad-CAM++ (2018)\n",
    "\n",
    "* **Idea:** ajusta la forma de calcular los pesos $\\alpha_k^c$ para tener en cuenta múltiples instancias de un mismo objeto en la imagen.\n",
    "* **Pro:** produce mapas más precisos en escenarios complejos y con objetos superpuestos.\n",
    "* **Con:** mayor costo computacional y complejidad en el cálculo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcbebcd",
   "metadata": {},
   "source": [
    "#### Comparación de métodos de explicabilidad basados en Grad-CAM\n",
    "\n",
    "**Figura 4**: Comparación de métodos de explicabilidad basados en Grad-CAM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
